{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=../figures/Brown_logo.svg width=50%>\n",
    "\n",
    "# Data-Driven Design & Analyses of Structures & Materials (3dasm)\n",
    "\n",
    "## Lecture 24\n",
    "\n",
    "### Miguel A. Bessa | <a href = \"mailto: miguel_bessa@brown.edu\">miguel_bessa@brown.edu</a>  | Associate Professor\n",
    "\n",
    "### Suryanarayanan M. S. | <a href = \"mailto: s.manojsanu@tudelft.nl\">s.manojsanu@tudelft.nl</a>  | PhD Candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline for today's lecture\n",
    "\n",
    "<!-- <img align=right src=./figures/grr.png width=60%> -->\n",
    "\n",
    "A brief introduction to optimization (for machine learning):\n",
    "\n",
    "* Optimization problem formulation: Objective, variables and constraints\n",
    "* Characteristics of optimization problems: Modality, and convexity\n",
    "* Solving optimization problems: Broad classification of optimizers; recall Taylor series expansion\n",
    "\n",
    "**References:**\n",
    "* J. R. R. Martins & Andrew Ning, Engineering Design Optimization, 2021 - Chapters 1 & 4\n",
    "* For practical details of algorithms (Extra):\n",
    "    * Nocedal, Jorge, and Stephen J. Wright. Numerical optimization. Springer Science & Business Media, 2006."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why optimization?\n",
    "\n",
    "Optimization is a central field in Engineering. It appears in multiple parts of the data-driven process.\n",
    "\n",
    "<img src=./figures/blocks.png width=100%>\n",
    "\n",
    "In Machine Learning, we saw that optimization is used when finding Point Estimates at 3 levels:\n",
    "\n",
    "1. Level 1: Finding a Point Estimate of parameters of a model\n",
    "    *  $\\hat{\\mathbf{z}} \\in \\underset{\\mathbf{z}}{\\mathrm{argmin}} \\left[\\mathcal{L}(\\mathbf{z})\\right]$, where $\\mathcal{L}(\\mathbf{z})$ is the loss function (the negative log posterior) and $\\mathbf{z}$ are the model parameters.\n",
    "\n",
    "2. Level 2: Finding a Point Estimate of the hyperparameters of a model\n",
    "    * Hyperparameters are usually *continuous*, but they can also be *discrete* (and a mixture).\n",
    "\n",
    "3. Level 3: Finding the best model or model structure\n",
    "    * Typically this is a *discrete* search: choose best among $\\mathcal{M}_1$, $\\mathcal{M}_2$, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Note**: Sometimes it is difficult to distinguish between (discrete) \"hyperparameters\" and \"model structures\". Often, that distinction becomes clear in context. Recall that:\n",
    "\n",
    "* \"Hyperparameter\" is a parameter associated to a particular model or model structure. All hyperparameters should be at the same \"level\" (Level 2, i.e. a level above the parameters of a model).\n",
    "\n",
    "* \"Model structure\" implies that this search happens at Level 3, i.e. each model structure is usually associated to a unique set of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's recall some practical examples of the different levels of Model Selection:\n",
    "\n",
    "* **Example 1**: Consider a **Linear Regression Model** ($\\mathcal{M}_1$) whose **parameters are weights**, the **hyperparameters** are the **degree of the polynomial** (integer) and the **regularization strength** (continuous hyperparameter). And consider a **Gaussian process model** ($\\mathcal{M}_2$) which has no parameters, and the **hyperparamaters** are the **kernel parameters**. Then:\n",
    "\n",
    "    * **Level 3** is the selection of the best model between $\\mathcal{M}_1$ and $\\mathcal{M}_2$.\n",
    "    * **Level 2** is the hyperparameter optimization for each model, leading to $\\hat{\\boldsymbol{\\theta}}$ (note that in this case the hyperparameters are different for each model).\n",
    "    * **Level 1** only requires optimization for the Linear Regression Model (to find the \"optimal\" weights $\\hat{\\mathbf{z}}$ for each $\\boldsymbol{\\theta}$ of $\\mathcal{M}_1$). The Gaussian Process model is obtained by Bayesian inference at Level 1, so this model ($\\mathcal{M}_2$) does not require optimization at this level.\n",
    "\n",
    "Note: **In this case**, Level 2 requires to use an optimization algorithm capable of simultaneously optimizing for *discrete* and *continuous* variables! There are many optimizers that **cannot** do that well (the ones that can are usually called *Mixed-Integer Programming*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Example 2**: Alternatively, it is useful to understand that **we can define different levels** even when only considering Linear Regression. The parameters would be the weights ($\\mathbf{z}$), but the **hyperparameter would now be the regularization strength** ($\\theta$), while the **polynomial degree could be considered a model structure** ($\\mathcal{M}$). Then:\n",
    "\n",
    "    * **Level 3** would be the choice of each model structure $\\mathcal{M}_1$ (e.g. Linear Regression with polynomial basis of degree 2), $\\mathcal{M}_2$ (Linear regression with degree 3), etc.\n",
    "    * **Level 2** would be the hyperparameter optimization for each model, i.e. finding the \"best\" regularization strength $\\hat{\\theta}$ for each model structure.\n",
    "    * **Level 1** is the optimization of the weights $\\mathbf{z}$ (for each hyperparameter $\\theta$ of each model structure $\\mathcal{M}_i$)\n",
    "\n",
    "Note: In this case, the above-mentioned Level 2 requires simpler (and more common) optimization algorithms that only deal with continuous variables. Level 3 may not even require the use of optimization algorithms, as it is simply choosing the best model structure by its performance (the ExperimentData table of f3dasm from where you pick the best model as you did in the Homework). Level 1 is usually in-built on machine learning packages, as every method usually already has common optimizers that can be chosen to find its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I am sharing this with you just to highlight that there are different ways of setting up your Model Selection strategy, as it depends on the problem you are trying to solve, the optimization algorithms you are familiar with, and the computational resources you have available..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ideally, becoming an expert in machine learning should imply becoming an expert in optimization...\n",
    "\n",
    "In practice... That's not always the case..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This course will only give you a very basic introduction about optimization algorithms, and it will not cover mixed-integer programming. So, we will just focus on some simple gradient-based optimizers, and you will also explore some gradient-free optimizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization: formalism\n",
    "\n",
    "General formulation of an optimization  problem:\n",
    "\n",
    "$\\begin{align}\n",
    "\\text{minimize} \\quad & f(\\mathbf{x}) \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "$\\begin{align}\n",
    "\\text{by varying} \\quad & \\underline{x}_i \\leq \\ x_i \\leq \\overline{x}_i  & i=1,...,D_{x}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "$\\begin{align}\n",
    "\\text{subject to} \\quad & g_j(\\mathbf{x}) \\leq 0  & j=1,...,N_g \\\\\n",
    "                        & h_l(\\mathbf{x}) = 0  & l=1,...,N_h\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "* $\\mathbf{x}$ are decision variables.\n",
    "    * $\\underline{x}_i$ and $\\overline{x}_i$ are the lower and upper bounds of input $x_i$ for each of the $D_{x}$ input dimensions.\n",
    "* $f(\\mathbf{x})$ is the objective function (e.g. the loss function)\n",
    "* $\\mathbf{g}$ is the vector with all $N_g$ inequality constraint functions, and $\\mathbf{h}$ the $N_h$ equality constraint functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Note:** Sometimes the constraints can be written differently in different software packages and even for different algorithms.\n",
    "\n",
    "The formulation we wrote above is called the LHS form. Different textbooks follow different conventions.\n",
    "\n",
    "For example, you can see how [SciPy](https://docs.scipy.org/doc/scipy/tutorial/optimize.html#constrained-minimization-of-multivariate-scalar-functions-minimize) summarizes its optimization algorithms. For example, you can see that `SLSQP` uses a combined LHS and RHS formulation, but and `trust-constr` uses RHS formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A. Decision variables or Design variables\n",
    "        \n",
    "<img style=\"float: right;\" src=\"./figures/dvs.png\" width=20%>\n",
    "\n",
    "* Represent the space of possibilities (a.k.a. design space)\n",
    "    * This is the space that will be searched for the best solution\n",
    "* Variables can be:\n",
    "    * continuous or discrete\n",
    "    * Bounded or unbounded\n",
    "    * No. of design variables = dimensionality\n",
    "    * Physically meaningful or abstract\n",
    "        * E.g. thickness of a beam or parameters of a model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### B. Objective function\n",
    "\n",
    "<img style=\"float: right;\" src=\"./figures/objective.png\" width=30%>\n",
    "\n",
    "* Performance metric to be optimized\n",
    "\n",
    "* Single or multiple objectives are possible\n",
    "\n",
    "    * E.g. Cost vs quality, Weight vs stiffness etc.\n",
    "\n",
    "* Can be linear or non-linear (in the design variables)\n",
    "\n",
    "* May have different meanings\n",
    "    * E.g. weight of a beam or loss of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Note**: Recall that optimization is often formulated as a minimization problem. Maximization problems can be converted to minimization problems by multiplying the objective function by -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### C. Constraints\n",
    "\n",
    "<img style=\"float: right;\" src=\"./figures/constraint.png\" width=30%>\n",
    "\n",
    "\n",
    "* Functions that limit the design space.\n",
    "    * Linear or non-linear\n",
    "    * E.g. Stress in a beam $\\leq$ yield stress of the material.\n",
    "\n",
    "* Make optimization much more difficult.\n",
    "    * Solution has to be **feasible** (not violate any constraints)\n",
    "    * Solution has to be **optimal** (best possible solution)\n",
    "\n",
    "* Equality or inequality\n",
    "    * Inequality is more difficult to handle!\n",
    "    * They can be on or off (active or inactive)\n",
    "    \n",
    "Note: Bounds on the design variables are often also called **box constraints**. However, these are trivial to handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Narrowing our focus\n",
    "\n",
    "- Optimization is extremely vast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Fortunately, the vast majority of optimization scenarios needed in machine learning involve:\n",
    "    - Discrete or continuous decision variables\n",
    "    - Single objective\n",
    "    - Trivial constraints (just box constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Good news**: Most optimization scenarios in machine learning are formulates as\n",
    "\n",
    "$\\begin{align}\n",
    "\\text{minimize} \\quad & f(\\mathbf{x}) \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "$\\begin{align}\n",
    "\\text{by varying} \\quad & \\underline{x}_i \\leq \\ x_i \\leq \\overline{x}_i  & i=1,...,D_x\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- What about the **bad news**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Most Engineering applications often involve nontrivial constraints.\n",
    "\n",
    "* Your Final project will illustrate this (quite simplified).\n",
    "\n",
    "But we will not explicitly cover constrained optimization in the lectures. You'll have to get creative!\n",
    "\n",
    "There are some simple ways to handle contraints that all of you will immediately think about. But there are more sophisticated ways..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Characteristics of an optimization problem\n",
    "\n",
    "* Optimization problems usually have some key attributes that:\n",
    "    * Help categorize the problem and candidate optimization algorithms to consider\n",
    "    * Eventually helping to get better solutions with less resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Examples of important attributes are:\n",
    "    * Smoothness of the functions involved\n",
    "    * Linearity\n",
    "    * Stochasticity\n",
    "    * **Modality**\n",
    "    * **Convexity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modality\n",
    "\n",
    "<img align=right src=\"./figures/modality.png\" width=30%>\n",
    "\n",
    "**Modes** (i.e. minima) are points that are better than their neighbours\n",
    "\n",
    "Formally:\n",
    "\n",
    "$\\mathbf{x}^*$ is a minima if $f(\\mathbf{x}^*) \\leq f(\\mathbf{x})$ for every $\\mathbf{x} \\in \\{||\\mathbf{x} - \\mathbf{x}^*|| < \\epsilon\\ , \\epsilon > 0 \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Global minima vs local minima:\n",
    "\n",
    "* Multi-modal functions are much more difficult to optimize (just like multi-modal distributions are difficult to integrate)\n",
    "    * Risks of getting stuck in local minima\n",
    "    * Every global minimum is also a local minimum..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **So, how do we know we found the global optimum?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In general, we don't know... üòÆ‚Äçüí®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convexity\n",
    "\n",
    "* Purely mathematical\n",
    "* **Golden rule: If an optimization problem is convex, all local minima are global minima**\n",
    "\n",
    "\n",
    "* What is a convex optimization problem ?\n",
    "    * If all functions involved are convex\n",
    "    * ...\n",
    "\n",
    "* Convex functions should meet 2 criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**A** : *The line segment joining any two points of the graph of the function has to be above the function itself.*\n",
    "* For any two points $\\mathbf{x}_i, \\mathbf{x}_j$ in the domain of $f$ and variable $0 \\leq \\alpha \\leq 1$ :\n",
    "    \n",
    "$$f(\\alpha \\mathbf{x}_i + (1 - \\alpha) \\mathbf{x}_j) \\leq \\alpha f(\\mathbf{x}_i) + (1 - \\alpha) f(\\mathbf{x}_j)$$\n",
    "<img align=centre src=\"./figures/convexity.png\" width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**B** : *The domain of the function should not have holes*\n",
    "* The line segment joining two points of a set should also lie in the set\n",
    "* For continuous design variables in unconstrained settings, this is always valid\n",
    "\n",
    "<img align=centre src=\"./figures/convexity.png\" width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The **bad news**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Except some simple models (e.g. linear regression), **most ML models have (severely) non-convex loss** functions (i.e. negative log posterior, or negative log likelihood if there is no prior)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Solving optimization problems\n",
    "\n",
    "* Searching the design space = optimizers\n",
    "* Choice of optimizer is dependent on problem characteristics\n",
    "    * No-free lunch theorem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classifying optimization algorithms\n",
    "\n",
    "<img align=centre src=\"./figures/optimizers.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. **Search strategy**\n",
    "    * Local: Search in the vicinity of their initialization\n",
    "        * **Exploitative** nature\n",
    "        * Finds the nearest minima\n",
    "        \n",
    "    * Global: Search the entire design space (or try)\n",
    "        * **Exploratory** in nature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. **Algorithm design**\n",
    "    * Heuristics\n",
    "        * Nature inspired or based on rules-of-thumb\n",
    "        * Robust (fewer assumptions) & general\n",
    "    * Mathematically designed\n",
    "        * Strictly converge to an optimal point*.\n",
    "        * Works well when the assumptions match the problem\n",
    "        * Very efficient\n",
    "        * Difficult to design and implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3. **Order of information used**\n",
    "    * Practically, the most important classification\n",
    "    * Lets dive a bit deeper!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Taylor series and order of information\n",
    "\n",
    "\n",
    "* Approximating a function $f$ at a given point $x_0$\n",
    "    \n",
    "$$f(x + \\alpha)|_{x=x_0} \\approx f(x_0) + \\frac{df}{dx}\\Big\\lvert_{x=x_0} \\alpha + \\frac{1}{2}\\frac{d^2 f}{d x^2}\\Big\\lvert_{x=x_0}\\alpha^2 + \\mathcal{O}(\\alpha^3)$$ \n",
    "\n",
    "* $\\alpha$ is the perturbation\n",
    "    * Since there is one direction, the perturbation is along the derivatives\n",
    "* More terms imply a better approximation\n",
    "    * The error in the approximation scales as $\\alpha^{n+1}$, if we include only $n$ terms\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we have $D_x$ dimensions for the input variables:\n",
    "\n",
    "$$ f(\\mathbf{x} + \\alpha \\mathbf{p})|_{\\mathbf{x}=\\mathbf{x}_0} \\approx f(\\mathbf{x}_0) + \\alpha \\nabla f(\\mathbf{x}_0)^T \\mathbf{p} + \\frac{1} {2}\\alpha^2 \\mathbf{p}^T   \\mathbf{H}(\\mathbf{x}_0)   \\mathbf{p}$$\n",
    "\n",
    "* The main difference is that we perturb along a given direction!\n",
    "* This is the form used by many optimization algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Three terms in the series\n",
    "    * **Zeroth order term**: value of the function at the $\\mathbf{x}$ (our point of interest)\n",
    "    \n",
    "    * **First order term**: gradient of $f$ wrt to $\\mathbf{x}$, i.e. vector of partial derivatives\n",
    "        - Generalization of the first-derivative to $D_{\\text{in}}$ dimensions:\n",
    "         $$ \\nabla f(\\mathbf{x}) = \\Big[\\frac{\\partial f}{ \\partial x_1}, \\frac{\\partial f}{ \\partial x_2} ..., \\frac{\\partial f}{ \\partial x_{D_x}} \\Big]^T$$\n",
    "        - Direction is the steepest **ascent** of the function. i.e. the direction in which the function increases the fastest\n",
    "            * (if you want to minimize, you want to go in the opposite direction of the gradient, i.e. the direction of steepest **descent**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Second order term**: Hessian of $f$ wrt $\\mathbf{x}$, i.e.  matrix of second-order derivatives\n",
    "    - Generalization of the second-derivative to $D_\\text{in}$ dimensions. It is a symmetric matrix with size $D_\\text{in}\\times D_\\text{in}$:\n",
    "$$ H(\\mathbf{x}) = \\begin{bmatrix} \\frac{\\partial^2 f}{\\partial x_1^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_{D_x}} \\\\ \\vdots &  \\ddots & \\vdots \\\\ \\frac{\\partial^2 f}{\\partial x_{D_x} \\partial x_1} & \\cdots & \\frac{\\partial^2 f}{\\partial x_{D_x}^2} \\end{bmatrix} $$\n",
    "\n",
    "    - This matrix represents the curvature of the function (since it is a change in the gradients!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Zeroth-order optimizers (also called black-box optimizers)\n",
    "    * Use only function evaluations\n",
    "    * Common in hyperparameter tuning\n",
    "* First-order optimizers\n",
    "    * Gradient-based optimizers\n",
    "    * Overwhelming majority of ML optimizers\n",
    "* Second-order optimizers\n",
    "    * Theoretically faster than first-order, but memory intensive and computationally costly\n",
    "    * Unpopular in ML. Could this ever change?\n",
    "        * E.g. K-FAC, Shampoo etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "* Optimizers are algorithms for searching solutions within a design (or decision) space\n",
    "* General form of an optimization problem\n",
    "* Constraints make optimization difficult\n",
    "* Convex optimization problems are super nice... But not common in ML...\n",
    "\n",
    "**Next lecture**\n",
    "* More about optimizers\n",
    "* Optimality criteria (to identify minima)\n",
    "* Automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### See you next class\n",
    "\n",
    "Have fun!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:3dasm]",
   "language": "python",
   "name": "conda-env-3dasm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
