{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=../figures/Brown_logo.svg width=50%>\n",
    "\n",
    "## Data-Driven Design & Analyses of Structures & Materials (3dasm)\n",
    "\n",
    "## Lecture 25\n",
    "\n",
    "### Miguel A. Bessa | <a href = \"mailto: miguel_bessa@brown.edu\">miguel_bessa@brown.edu</a>  | Associate Professor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**What:** A lecture of the \"3dasm\" course\n",
    "\n",
    "**Where:** This notebook comes from this [repository](https://github.com/bessagroup/3dasm_course)\n",
    "\n",
    "**Reference for entire course:** Murphy, Kevin P. *Probabilistic machine learning: an introduction*. MIT press, 2022. Available online [here](https://probml.github.io/pml-book/book1.html)\n",
    "\n",
    "**How:** We try to follow Murphy's book closely, but the sequence of Chapters and Sections is different. The intention is to use notebooks as an introduction to the topic and Murphy's book as a resource.\n",
    "* If working offline: Go through this notebook and read the book.\n",
    "* If attending class in person: listen to me (!) but also go through the notebook in your laptop at the same time. Read the book.\n",
    "* If attending lectures remotely: listen to me (!) via Zoom and (ideally) use two screens where you have the notebook open in 1 screen and you see the lectures on the other. Read the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Optional reference (the \"bible\" by the \"bishop\"... pun intended ðŸ˜†) :** Bishop, Christopher M. *Pattern recognition and machine learning*. Springer Verlag, 2006.\n",
    "\n",
    "**References/resources to create this notebook:**\n",
    "* This simple tutorial is still based on a script I created for this article: https://imechanica.org/node/23957\n",
    "* It follows from some examples provided by the scikit-learn user guide, which seem to have originated from Mathieu Blondel, Jake Vanderplas, Vincent Dubourg, and Jan Hendrik Metzen.\n",
    "\n",
    "Apologies in advance if I missed some reference used in this notebook. Please contact me if that is the case, and I will gladly include it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## **OPTION 1**. Run this notebook **locally in your computer**:\n",
    "1. Confirm that you have the '3dasm' mamba (or conda) environment (see Lecture 1).\n",
    "2. Go to the 3dasm_course folder in your computer and pull the last updates of the [repository](https://github.com/bessagroup/3dasm_course):\n",
    "```\n",
    "git pull\n",
    "```\n",
    "    - Note: if you can't pull the repo due to conflicts (and you can't handle these conflicts), use this command (with **caution**!) and your repo becomes the same as the one online:\n",
    "        ```\n",
    "        git reset --hard origin/main\n",
    "        ```\n",
    "3. Open command window and load jupyter notebook (it will open in your internet browser):\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "5. Open notebook of this Lecture and choose the '3dasm' kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## **OPTION 2**. Use **Google's Colab** (no installation required, but times out if idle):\n",
    "\n",
    "1. go to https://colab.research.google.com\n",
    "2. login\n",
    "3. File > Open notebook\n",
    "4. click on Github (no need to login or authorize anything)\n",
    "5. paste the git link: https://github.com/bessagroup/3dasm_course\n",
    "6. click search and then click on the notebook for this Lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Basic plotting tools needed in Python.\n",
    "\n",
    "import matplotlib.pyplot as plt # import plotting tools to create figures\n",
    "import numpy as np # import numpy to handle a lot of things!\n",
    "from IPython.display import display, Math # to print with Latex math\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\" # render higher resolution images in the notebook\n",
    "plt.rcParams[\"figure.figsize\"] = (8,4) # rescale figure size appropriately for slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline for today\n",
    "\n",
    "* Training Artificial Neural Networks\n",
    "\n",
    "**Reading material**: This notebook + (ANNs in Chapter 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap of last lecture\n",
    "\n",
    "* We learned that the common point estimates of ANNs (MLE or MAP) are obtained by minimizing a loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* For example, if we assume a Gaussian observation distribution we obtain the $\\ell_2$ loss function (with or without regularization, depending on the prior distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* For the uniform prior we arrived to the following result:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{z}}_{\\text{mle}} = \\underset{z}{\\mathrm{argmin}}\\left\\{\\mathcal{L}\\left[(\\mathbf{x},\\mathbf{y}), \\mathbf{z} \\right] \\right\\} = \\underset{z}{\\mathrm{argmin}}\\left[\\frac{1}{2}\\sum_{n=1}^{N}\\left[\\mathbf{y}_n-\\mathbf{f}(\\mathbf{x}_n;\\, \\mathbf{z})\\right]^T\\left[\\mathbf{y}_n-\\mathbf{f}(\\mathbf{x}_n;\\, \\mathbf{z})\\right] \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Therefore, **we need to minimize the loss function**: $\\mathcal{L}\\left[(\\mathbf{x},\\mathbf{y}), \\mathbf{z} \\right] = \\frac{1}{2} ||\\mathbf{Y}-\\mathbf{f}(\\mathbf{X},\\mathbf{z}) ||_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Minimizing the loss function with gradient-based optimizers\n",
    "\n",
    "There are many optimization algorithms that can be used to minimize the loss function.\n",
    "\n",
    "* The most common choices involve the use of first-order optimizers, i.e. optimizers that use the gradient of the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to calculate the gradient of the loss function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The mean function of an ANN with $L$ hidden layers is then a composition of $L+1$ functions:\n",
    "\n",
    "$\\mathbf{f} = \\mathbf{f}_{L+1} \\circ \\mathbf{f}_L \\circ \\ldots \\circ \\mathbf{f}_{2} \\circ \\mathbf{f}_1 $\n",
    "\n",
    "And if we denote $f_{L+2} = \\mathcal{L}$ as the loss function, then we can write the loss function as follows:\n",
    "\n",
    "$\\mathcal{L} = f_{L+2} \\circ \\mathbf{f}_{L+1} \\circ \\mathbf{f}_L \\circ \\ldots \\circ \\mathbf{f}_{l} \\circ \\ldots \\circ \\mathbf{f}_{2} \\circ \\mathbf{f}_1 $\n",
    "\n",
    "Where $l=1,\\ldots, L$ are the hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The next slide makes it less abstract, by considering the example of an ANN with **1 hidden layer** and the $\\ell_2$ loss (i.e. regression case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Neurons of ANN with **1 hidden layer** and using $\\ell_2$ loss (i.e. regression case).\n",
    "\n",
    "* Layer 0 (input layer): $\\mathbf{n}_0 \\equiv \\mathbf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Layer $L=1$ (first hidden layer):\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbf{n}_L &= \\mathbf{n}_1 \\\\\n",
    "             &= \\mathbf{f}_L(\\mathbf{n}_{L-1}, \\mathbf{z}_{L-1}) \\\\\n",
    "             &= \\mathbf{f}_1(\\mathbf{n}_0, \\mathbf{z}_0) \\\\\n",
    "             &= \\mathbf{f}_1(\\mathbf{b}_0 + \\mathbf{W}_0\\mathbf{n}_0)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Layer $L+1=2$ (output layer):\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbf{n}_{L+1} &= \\mathbf{n}_2 \\equiv \\mathbf{y} \\\\\n",
    "           &= \\mathbf{f}_{L+1}(\\mathbf{n}_{L}, \\mathbf{z}_{L}) = \\mathbf{f}_2(\\mathbf{n}_1, \\mathbf{z}_1) \\\\ \n",
    "           &= \\mathbf{f}_2(\\mathbf{b}_1 + \\mathbf{W}_1\\mathbf{n}_1) & \\\\\n",
    "           &= \\mathbf{b}_1 + \\mathbf{W}_1\\mathbf{n}_1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "(The last line results from using a linear activation function for the **output layer**, i.e. layer $L+1$, when we are solving a regression problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Layer $L+2$ can be considered the loss function:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathcal{L} &= f_{L+2}(\\mathbf{n}_{L+1}, \\mathbf{y})\\\\\n",
    "            &= f_3(\\mathbf{n}_2, \\mathbf{y}) \\\\\n",
    "            &= \\frac{1}{2}|| \\mathbf{y} - \\mathbf{n}_2  ||_2^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where, again, we are considering here the $\\ell_2$ loss because we are focusing on a regression case. If it was a classification problem we would consider the cross-entropy loss (see Lecture 21)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can calculate the derivatives of the loss function wrt to the unknowns $\\mathbf{z}$ very easily!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In order to calculate the derivatives of the loss function:\n",
    "\n",
    "$\\mathcal{L} = f_{L+2} \\circ \\mathbf{f}_{L+1} \\circ \\mathbf{f}_L \\circ \\ldots \\circ \\mathbf{f}_{2} \\circ \\mathbf{f}_1 $\n",
    "\n",
    "we just need to use the chain rule!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's start by taking the derivative of the loss wrt the unkowns of the last layer, i.e. $\\mathbf{z}_L$:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\nabla_{\\mathbf{z}_{L}} \\mathcal{L} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_L} &= \\frac{\\partial f_{L+2}}{\\partial \\mathbf{z}_{L}} \\\\\n",
    "&= \\frac{\\partial f_{L+2}}{\\partial \\mathbf{f}_{L+1}} \\frac{\\partial \\mathbf{f}_{L+1}}{\\partial \\mathbf{z}_{L}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Which is usually presented as: $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_L} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{n}_{L+1}} \\frac{\\partial \\mathbf{n}_{L+1}}{\\partial \\mathbf{z}_{L}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}} \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{z}_{L}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "but we should not stop here! Remember, we want all the derivatives of the loss wrt to all the unknowns $\\mathbf{z}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So, taking the derivative of the loss wrt the unkowns of the next hidden layer, i.e. wrt $\\mathbf{z}_{L-1}$:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\nabla_{\\mathbf{z}_{L-1}} \\mathcal{L} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_{L-1}} &= \\frac{\\partial f_{L+2}}{\\partial \\mathbf{z}_{L-1}} \\\\\n",
    "&= \\frac{\\partial f_{L+2}}{\\partial \\mathbf{f}_{L+1}} \\frac{\\partial \\mathbf{f}_{L+1}}{\\partial \\mathbf{f}_{L}} \\frac{\\partial \\mathbf{f}_{L}}{\\partial \\mathbf{z}_{L-1}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Which is usually presented as:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_{L-1}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{n}_{L+1}} \\frac{\\partial \\mathbf{n}_{L+1}}{\\partial \\mathbf{n}_{L}} \\frac{\\partial \\mathbf{n}_{L}}{\\partial \\mathbf{z}_{L-1}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}} \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{n}_{L}} \\frac{\\partial \\mathbf{n}_{L}}{\\partial \\mathbf{z}_{L-1}}\n",
    "$$\n",
    "\n",
    "but we should not stop here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So, taking the derivative of the loss wrt $\\mathbf{z}_{l}$:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\nabla_{\\mathbf{z}_{l}} \\mathcal{L} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_{l}} &= \\frac{\\partial f_{L+2}}{\\partial \\mathbf{z}_{l}} \\\\\n",
    "&= \\frac{\\partial f_{L+2}}{\\partial \\mathbf{f}_{L+1}} \\frac{\\partial \\mathbf{f}_{L+1}}{\\partial \\mathbf{f}_{L}} \\cdots \\frac{\\partial \\mathbf{f}_{l+2}}{\\partial \\mathbf{f}_{l+1}}\\frac{\\partial \\mathbf{f}_{l+1}}{\\partial \\mathbf{z}_{l}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Which is usually presented as:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_{L-1}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{n}_{L+1}} \\frac{\\partial \\mathbf{n}_{L+1}}{\\partial \\mathbf{n}_{L}} \\cdots \\frac{\\partial \\mathbf{n}_{l+2}}{\\partial \\mathbf{n}_{l+1}}\\frac{\\partial \\mathbf{n}_{l+1}}{\\partial \\mathbf{z}_{l}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}} \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{n}_{L}} \\cdots \\frac{\\partial \\mathbf{n}_{l+2}}{\\partial \\mathbf{n}_{l+1}}\\frac{\\partial \\mathbf{n}_{l+1}}{\\partial \\mathbf{z}_{l}}\n",
    "$$\n",
    "\n",
    "but we should not stop here! We need to keep going until we reach the first layer of the network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So, taking the derivative of the loss wrt $\\mathbf{z}_{0}$:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\nabla_{\\mathbf{z}_{0}} \\mathcal{L} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_{0}} &= \\frac{\\partial f_{L+2}}{\\partial \\mathbf{z}_{l}} \\\\\n",
    "&= \\frac{\\partial f_{L+2}}{\\partial \\mathbf{f}_{L+1}} \\frac{\\partial \\mathbf{f}_{L+1}}{\\partial \\mathbf{f}_{L}} \\cdots \\frac{\\partial \\mathbf{f}_{l+2}}{\\partial \\mathbf{f}_{l+1}}\\frac{\\partial \\mathbf{f}_{l+1}}{\\partial \\mathbf{z}_{l}} \\cdots \\frac{\\partial \\mathbf{f}_{2}}{\\partial \\mathbf{f}_{1}}\\frac{\\partial \\mathbf{f}_{1}}{\\partial \\mathbf{z}_{0}} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Which is usually presented as:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{z}_{L-1}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{n}_{L+1}} \\frac{\\partial \\mathbf{n}_{L+1}}{\\partial \\mathbf{n}_{L}} \\cdots \\frac{\\partial \\mathbf{n}_{l+2}}{\\partial \\mathbf{n}_{l+1}}\\frac{\\partial \\mathbf{n}_{l+1}}{\\partial \\mathbf{z}_{l}} \\cdots \\frac{\\partial \\mathbf{n}_{2}}{\\partial \\mathbf{n}_{1}}\\frac{\\partial \\mathbf{n}_{1}}{\\partial \\mathbf{z}_{0}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}} \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{n}_{L}} \\cdots \\frac{\\partial \\mathbf{n}_{l+2}}{\\partial \\mathbf{n}_{l+1}}\\frac{\\partial \\mathbf{n}_{l+1}}{\\partial \\mathbf{z}_{l}} \\cdots \\frac{\\partial \\mathbf{n}_{2}}{\\partial \\mathbf{n}_{1}}\\frac{\\partial \\mathbf{n}_{1}}{\\partial \\mathbf{z}_{0}} \n",
    "$$\n",
    "\n",
    "* And with this we finally computed all the deriavatives!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is what we call **Backpropagation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The partial derivatives of the neuron output with respect to the previous neuron outputs are organized in a matrix called the **Jacobian**:\n",
    "\n",
    "$$\n",
    "\\mathbf{J}_{\\mathbf{f}_{l+1}}(\\mathbf{n}_l) = \\frac{\\partial \\mathbf{f}_{l+1}(\\mathbf{n}_{l})}{\\partial \\mathbf{n}_l} = \\begin{bmatrix}\\frac{\\partial f_{1, l+1}}{\\partial n_{1,l}} & \\cdots & \\frac{\\partial f_{d_{l+1}, l+1}}{\\partial n_{d_l,l}}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\partial f_{d_{l+1}, l+1}}{\\partial n_{1,l}} & \\cdots & \\frac{\\partial f_{d_{l+1}, l+1}}{\\partial n_{d_l,l}}\\end{bmatrix} =\n",
    "\\begin{bmatrix}\\nabla f_{1,l+1}(\\mathbf{n}_l)^T\\\\\n",
    "\\vdots\\\\\n",
    "\\nabla f_{d_{l+1}, l+1}(\\mathbf{n}_l)^T\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial \\mathbf{f}_{l+1}}{\\partial n_{0,l}}, & \\cdots & , \\frac{\\partial \\mathbf{f}_{l+1}}{\\partial n_{d_l,l}}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $d_{l+1}$ and $d_l$ are the number of neurons in layer $l+1$ and $l$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, doing backpropagation (chain rule) using Jacobians becomes:\n",
    "\n",
    "$$\n",
    "\\mathbf{J}_{\\mathbf{f}_{L+1}}(\\mathbf{n}_0) = \\mathbf{J}_{\\mathbf{y}}(\\mathbf{x}) = \\mathbf{J}_{\\mathbf{f}_{L+1}}(\\mathbf{n}_{L}) \\mathbf{J}_{\\mathbf{f}_{L}}(\\mathbf{n}_{L-1}) \\cdots \\mathbf{J}_{\\mathbf{f}_{l+1}}(\\mathbf{n}_{l}) \\cdots \\mathbf{J}_{\\mathbf{f}_{1}}(\\mathbf{n}_{0})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Backpropagation\n",
    "\n",
    "* Backpropagation is simply the computation of the gradients (derivatives) of the loss wrt to the unknowns $\\mathbf{z}$.\n",
    "\n",
    "    * Note: remember, \"loss function\" just means NLL (when using a uniform prior) or negative log joint likelihood (when using any other prior)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* These gradients are then provided to **a gradient-based optimizer** (e.g. in Lecture 23 we used a variant of gradient descent, called ADAM), that will then provide a point estimate (the weights and biases that minimize the error; or, alternatively, that maximize the joint likelihood)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the last part of the course, we will introduce the basics of **optimization**!\n",
    "\n",
    "* Optimization is the key to deterministic machine learning because it's what enables to find the point estimate for the unknowns (here: weights and biases) by minimizing the NLL (or negative log joint likelihood)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Note**: optimization is (obviously!) a separate discipline on its own! We will only have 3 classes about this topic! The main goal is to understand why we typically choose a particular algorithm for finding point estimates of particular models:\n",
    "\n",
    "- Example, L-BFGS is a common choice to find the point estimate of the hyperparameters of GPs, but we use simpler optimizers such as ADAM and Stochastic Gradient Descent to find the point estimate of the parameters of an ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### See you next class\n",
    "\n",
    "Have fun!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python [conda env:3dasm]",
   "language": "python",
   "name": "conda-env-3dasm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
