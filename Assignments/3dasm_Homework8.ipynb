{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1c05dc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2aa7b7b11ddcdec4a758a8b25da72e89",
     "grade": false,
     "grade_id": "cell-bce01a551d8dabe6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# ENGN2350 Data-Driven Design and Analysis of Structures and Materials\n",
    "\n",
    "_Homeworks for fall semester 2025-2026_\n",
    "\n",
    "Coding exercises to explore the [`f3dasm`](https://f3dasm.readthedocs.io/en/latest/) package.\n",
    "\n",
    "**General instructions**:\n",
    "\n",
    "- Read the questions and answer in the cells under the \"PUT YOUR CODE IN THE CELL BELOW\" message.\n",
    "- Work through the notebook and make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. You can remove the `'raise NotImplementedError()'` code.\n",
    "- After \"END OF YOUR CODE\" , there is a cell that contains simple tests (with `assert` statements) to see if you did the exercises correctly. Not all exercises have tests! If you run the cell containing the tests and no error is given, you have succesfully solved the exercise!\n",
    "- Make sure you have the right version of `f3dasm` (2.1.0).\n",
    "\n",
    "> You can check your `f3dasm` version by running `pip show f3dasm`\n",
    "\n",
    "- **ONLY WORK ON THE EXERCISE IN A JUPYTER NOTEBOOK ENVIRONMENT**\n",
    "\n",
    "> The homework assignments are generated and automatically graded by the `nbgrader` extension. If you open and save the notebook in Google Colab, metadata from Colab will be added, and the `nbgrader` metadata will be altered. As a result, `nbgrader` will be unable to automatically grade your homework. Therefore, we kindly ask students to only work on the notebook in Jupyter Notebook.\n",
    "\n",
    "- **DO NOT ADD OR REMOVE CELLS IN THE NOTEBOOK**\n",
    "\n",
    "> Most cells containing tests are set to read-only, but VS Code can bypass this restriction. Modifying or removing cells in the notebook may disrupt the `nbgrader` system, preventing automatic grading of your homework.\n",
    "\n",
    "**Instructions for handing in the homework**\n",
    "\n",
    "- Upload the Jupyter Notebook (`.ipynb file`) to Canvas\n",
    "\n",
    "If there are any questions about the homework, send an email to Samik (samik_mukhopadhyay@brown.edu) or Elvis (elvis_alexander_aguero_vera@brown.edu)\n",
    "\n",
    "**Grading**\n",
    "\n",
    "- In each homework, you can obtain a maximum of 20 points\n",
    "- Next to each subquestion, the maximum amount of obtainable points is listed\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd2b31",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40ada260916a8fcb3dcb0a68252395fa",
     "grade": false,
     "grade_id": "cell-29cde56aff653320",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can put your name in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c6041",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45c2bf59ec09d762fd2d607eb147c1a4",
     "grade": false,
     "grade_id": "cell-925719e94f410246",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dac51d",
   "metadata": {},
   "source": [
    "## Homework 8\n",
    "\n",
    "In this homework you will explore advanced usage of the `f3dasm` package\n",
    "\n",
    "At the end of this homework you will know\n",
    "- how to use the built-in defaults of `f3dasm`\n",
    "- how to evaluate different sampling techniques in a structured way with `f3dasm`\n",
    "- how to use `f3dasm` for hyperparameter analysis for classification methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e4e94-5cce-4bb2-adcd-9aa1b90f89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some packages we might need later\n",
    "import numpy as np\n",
    "import f3dasm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebffe34-6199-459f-a2a7-03eaa8d54b83",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 1\n",
    "\n",
    "We will explore the default built-in implementation that are available in `f3dasm`.\n",
    "You can learn more about those in the [documentation page](https://f3dasm.readthedocs.io/en/latest/rst_doc_files/defaults.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc8ab0f-44df-43dc-9dd3-e71bfdc1ff79",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1.1 _(1 point)_ Create Domain with one array-parameter named `'x'` with bounds $-32.768$ and $32.768$ and shape `(3,)` and name the domain `domain_3d`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee3b05-d62e-4277-8909-a557df356dd7",
   "metadata": {},
   "source": [
    "PUT YOUR CODE IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4971256-e655-4aaf-aa28-dfb8a8392c0e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e433bd7e220ddfd8ff9bd5584e68e31e",
     "grade": false,
     "grade_id": "cell-774c951f89dc9144",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b64eae4-dde6-458b-bc07-9fcdbdcb41cc",
   "metadata": {},
   "source": [
    "END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82595b8-7c53-4a7c-87b7-b8700de4cf06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "321fd7c8a1417f3e567ccd62ab86c4ab",
     "grade": true,
     "grade_id": "cell-6a5f23068e8cd549",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell checks if you did the exercise correctly\n",
    "assert isinstance(domain_3d, Domain)\n",
    "assert 'x' in domain_3d.array.input_names\n",
    "assert domain_3d.input_space['x'].shape == (3,)\n",
    "assert np.allclose(domain_3d.input_space['x'].lower_bound, -32.768)\n",
    "assert np.allclose(domain_3d.input_space['x'].upper_bound, 32.768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb355f8-9e4e-48cf-b649-12c11e3f196b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1.2 _(1 point)_ Use the built-in latin hypercube sampler to create 20 design points and name the result `experimentdata_3d`. Set the seed to $123$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c6fc45-fed8-4fcf-b0c3-d8288f70717b",
   "metadata": {},
   "source": [
    "PUT YOUR CODE IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36666806-787e-4afe-a1f7-5af9193b1fd9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e1b1a7ed985d94da2412451ae4a79ce",
     "grade": true,
     "grade_id": "cell-a3aa84fe820341bc",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04990284-ca00-4fa1-897c-0aa1bc59ac6c",
   "metadata": {},
   "source": [
    "END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5992d-2618-4dc0-a4e8-3ed7816a40b0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1.3 _(2 points)_ Plot all the points in 2D scatter plots for all possible combinations of the input features, i.e. every pair of features as $x$ and $y$ of the scatter plots. Observe the sampling points and how they are distributed in the domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e690f8-bc8f-424b-8e86-f60a24a039da",
   "metadata": {},
   "source": [
    "PUT YOUR CODE IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2cff4-df60-4526-aee3-8763d4cf7033",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea334dea7fc881b2651cb4a928e7e027",
     "grade": true,
     "grade_id": "cell-cb0c4ac287b6d5c8",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe760f3-437e-4838-8380-24d1f65c4348",
   "metadata": {},
   "source": [
    "END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf6fec-ade2-4696-a699-7f15baaabc81",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1.4 _(1 point)_ Evaluate all the designs with the built-in ['Ackley'](https://www.sfu.ca/~ssurjano/ackley.html) function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f9adb3-533e-40b0-953d-16fb09f01634",
   "metadata": {},
   "source": [
    "PUT YOUR CODE IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a7387-9883-48f9-af00-4869dfee88e0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2858a0bbf8383ef1852810c634b3979",
     "grade": true,
     "grade_id": "cell-ab743eef1e21a8de",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0debfb-4853-454c-9475-5b4bba468e28",
   "metadata": {},
   "source": [
    "END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b5d7d-d017-4989-a9fa-e1bd27c6f9b2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1.5 _(1 points)_ Optimize this experiment with the built-in Nelder-Mead optimizer for $50$ iterations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf177976-1485-4f0a-802b-d2879626e264",
   "metadata": {},
   "source": [
    "PUT YOUR CODE IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120996b7-abde-42dd-bd46-a88cc290b67f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf0712f1161fe906a7017aad2515348f",
     "grade": true,
     "grade_id": "cell-11fbcb8176d0e72f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c0540b-0709-414e-ac92-1cfe5e3b3fb4",
   "metadata": {},
   "source": [
    "END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702cc428",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 2\n",
    "\n",
    "In this next exercise, we are going to train a gaussian process regressor with data from built-in benchmark functions.\n",
    "We are going to vary the benchmark function used, the sampling technique and the number of training points\n",
    "\n",
    "Before we start exploring, we want to create a dataset with the built-in benchmark functions.\n",
    "\n",
    "We would like to:\n",
    "- .. create a domain with an array parameter named `'x'` with bounds $x \\in [-5, 5]$ ;\n",
    "- .. sample $N$ points with a given sampler, using $123$ as the seed for the random number generator;\n",
    "- .. evaluate the samples on a given benchmark function and use `'y'` as the output name\n",
    "\n",
    "2.1 _(2 points)_ Make a function `create_data` that inputs the type of built-in sampler, the number of sampling points and the built-in benchmark function be evaluated. The function returns a `f3dasm.ExperimentData` object with those samples, evaluated by the benchmark function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d8047-e3bd-4543-bc14-d9a571e97177",
   "metadata": {},
   "source": [
    "PUT YOUR CODE IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e3ba8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b46ecf4339088d1c95adaa39201bba5",
     "grade": false,
     "grade_id": "cell-24039e8ef0107f0f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "def create_data(n_samples: int, sampler: str, benchmark_fn: str) -> f3dasm.ExperimentData:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return experiment_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0471a139-f989-4f81-96fc-445571fca2b9",
   "metadata": {},
   "source": [
    "END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1533b3-d062-4b7f-93d2-ba3bb8a16b08",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "963a61b8af7d05406e8e5167c916e554",
     "grade": true,
     "grade_id": "cell-d6394cee6b2e698d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell checks if you did the exercise correctly \n",
    "import numpy as np\n",
    "data_rastrigin = create_data(n_samples=300, sampler='random', benchmark_fn='rastrigin')\n",
    "data_ackley = create_data(n_samples=300, sampler='latin', benchmark_fn='ackley')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c25fd4",
   "metadata": {},
   "source": [
    "---\n",
    "2.2 _(1 points)_ Next, we are going to create a helper function that trains the model and returns error metrics in order to evaluate the predictions\n",
    "\n",
    "\n",
    "Create a function `evaluate_regressor` that requires the training data, `X_train` and `y_train`, the testing data `X_test` and `y_test` and the scikit-learn model `model`\n",
    "\n",
    "The function should :\n",
    "\n",
    "- standard scale both the input and the output data first\n",
    "- use the `model.fit` function to fit `X_train` and `y_train`\n",
    "- predict on `X_test` to create `y_pred`\n",
    "- calculate the $R^2$ and MSE on the testing data and return the two metrics as a tuple of two floats\n",
    "\n",
    "*Hint*: if you want to test your code, you can export the resulting `ExperimentData` from a `create_data` function call to a `numpy` array. However, the resulting `numpy` arrays are actually a nested list of numpy arrays. In order to stack the arrays, you can use the following code:\n",
    "\n",
    "```python\n",
    "X = np.stack(X.flatten())\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c23c74-ef0c-4a1a-ab12-d16934e86248",
   "metadata": {},
   "source": [
    "PUT YOUR CODE IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3581b5e1-eb87-44ae-a04e-19bf48ec6993",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c262a39fdd637e5e48e8d04134231d48",
     "grade": false,
     "grade_id": "cell-e13cbe76511613bd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "def evaluate_regressor(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray, model):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return r2, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aadbbc7-75f2-4a24-b47e-eeee700ef4da",
   "metadata": {},
   "source": [
    "END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa364e2-4c22-4aec-9639-fb8f299db4b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68f9dc22e54ddb9658c644c29d7eea8d",
     "grade": true,
     "grade_id": "cell-a2a603d59fda7c19",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell checks if you did the exercise correctly \n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = data_ackley.to_numpy()\n",
    "\n",
    "# X and y are nested list of arrays. The following operations make a single array for all samples and reshapes\n",
    "X = np.stack(X.flatten())\n",
    "y = np.stack(y.flatten())\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "model = GaussianProcessRegressor(random_state=123)\n",
    "r2, mse = evaluate_regressor(X_train, y_train, X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a4e7e2-bdc5-4aeb-ad1d-a34669851809",
   "metadata": {},
   "source": [
    "---\n",
    "2.3 _(4 points)_ Now we are putting everything together in a custom `DataGenerator` class:\n",
    "\n",
    "1. Create a new `Domain` object with 3 parameters:\n",
    "\n",
    "- `n_samples`, the number of training samples, as a categorical variable with possible values $12$, $25$ and $150$\n",
    "- `sampler`, the chosen built-in sampler, as a categorical variable with possible values `'random'`, `'sobol'` and `'latin'`\n",
    "- `benchmark_fn`, the chosen built-in benchmark function, as a categorical variable with possible values `'Styblinski Tang'`, `'Branin'` and `'Sphere'`\n",
    "\n",
    "2. Create an `ExperimentData` object from the domain and use the built-in `'grid'` sampler to create all possible combinations of `n_samples`, `sampler` and `benchmark_fn`\n",
    "> Hint: you should have an ExperimentData object with 27 different experiments\n",
    "\n",
    "3. Create a `EvaluateRegressor` class that inherits from `f3dasm.datageneration.DataGenerator`\n",
    "- Inside the `execute()` method:\n",
    "  - extract the values `n_samples` (type=`int`), `sampler` (type=`str`) and `benchmark_fn` (type=`str`) from the `experiment_sample` argument\n",
    "  - Create `X_train` and `y_train` by calling the `create_data` function with the extracted values created earlier\n",
    "  - Create `X_test` and `y_test` by calling the `create_data` function, but set `n_samples=100` and `sampler='random'`\n",
    "  - Create a GaussianProcessRegressor from `sklearn` with random seed $123$\n",
    "  - Call the `evaluate_regressor` function with the training data, testing data and GPR model\n",
    "  - Store the $R^2$ and the MSE values in the `experiment_sample` with names `r2` and `mse`\n",
    "\n",
    "4. Create an instance of the `EvaluateRegressor` class and `evaluate` the `ExperimentData` object.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ac6b8-1c0f-45c8-8b29-12ee78cc0b1d",
   "metadata": {},
   "source": [
    "PUT YOUR CODE IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcae2d6-c64b-482b-8c9e-a24aa0e88ea3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c4bda66311d7cdac70e02c9fe4435d2",
     "grade": true,
     "grade_id": "cell-e7bde3c97b6af6e5",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You might want to import some classes/functions\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc110e-4880-450e-a88a-c3b9e9fd0790",
   "metadata": {},
   "source": [
    "END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a999d0",
   "metadata": {},
   "source": [
    "---\n",
    "1.3 _(1 point)_ Reflect on your findings: Can you explain why certain the performance differs when changing the number of training points and the sampling technique?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddab0946-da85-4217-973f-48c5545ddf66",
   "metadata": {},
   "source": [
    "PUT YOUR WRITTEN ANSWER IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9b28f-a91b-493c-b6fc-6208437e784f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc10f5e9317cbba3de54b0357f33c59c",
     "grade": true,
     "grade_id": "cell-512054b2cf22d10e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf0fe3d-717d-4b2d-9da7-9ac84e13cc4d",
   "metadata": {},
   "source": [
    "END OF YOUR WRITTEN ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cbb289",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise 3\n",
    "\n",
    "We can also do hyperparameter investigation effectively with `f3dasm`.\n",
    "\n",
    "For the following exercise, we are going to investigate the influence of the regularization parameter $C$ of the [Suppor Vector Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) on the [iris dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris).\n",
    "\n",
    "3.1 _(1 point)_ Load the iris dataset from `scikit-learn`, select only the first two feature ('sepal length (cm)' and 'sepal width (cm)') and split the data in a 75/25 test and training set. Set the seed for the random number generator to $123$. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799771ad-f668-4034-a66c-13745d65891c",
   "metadata": {},
   "source": [
    "PUT YOUR CODE IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb96cc-e9c5-425d-98ef-f3ca2eb2adc9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6f57aa8eed14cc29e29e6efa7d1cdfd",
     "grade": false,
     "grade_id": "cell-45c087179d31db6c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24974bcd-4d0c-4dfe-9792-7316e8c6e37d",
   "metadata": {},
   "source": [
    "END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b3b3a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5aaf5a94f7d6e2040d7ec9c6df90541",
     "grade": true,
     "grade_id": "cell-b29f46c87533b824",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell checks if you did the exercise correctly\n",
    "assert (X_train[0] == [5.4, 3.9]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9604508-5c09-4929-ba67-4a50a8a1106e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "3.2 _(1 point)_ Create a domain object called `domain` with continuous parameter `C` and construct an `ExperimentData` object called `expeirment_data` with `Data_c` (given below)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac682d39-89fc-4eec-ad6e-066e4c365cca",
   "metadata": {},
   "source": [
    "PUT YOUR CODE IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1a5abd-a427-47e0-ad30-7edcd56d6ff3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ed0e4d132b5468939f4ef40e1664196",
     "grade": false,
     "grade_id": "cell-8a1d06cfd64eadc6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Data_c = np.logspace(-2.3, 2.5, 40)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663e8d9-e39e-4b1e-9d39-83a5e5e4de7c",
   "metadata": {},
   "source": [
    "END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3ad5d-4517-406b-b544-e4c594c45069",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88a1aaa7cd0561609d3ddf69bb144849",
     "grade": true,
     "grade_id": "cell-b1ad08be51def493",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell checks if you did the exercise correctly\n",
    "assert isinstance(domain, Domain)\n",
    "assert 'C' in domain.input_names\n",
    "assert domain.input_space['C']\n",
    "assert isinstance(experiment_data, ExperimentData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4eac42-462a-4b85-9e93-9355c0e283e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "3.3 _(2 points)_ Fill in the `evaluate_classifier` method and `execute` function of the `EvaluateClassifier` class below:\n",
    "- The `evaluate_classifier` takes in the model and fits it to `self.X_train`, `self.y_train`, predicts the labels of `self.X_test` and returns the accuracy of the predictions\n",
    "- The `execute` function extract the `C` parameter from `self.experiment_sample`, creates the Support Vector Classifier with the extracted $C$ value and `random_state=123`, calls the `evaluate_classifier` method and stores the accuracy value back to the `self.experiment_sample`.\n",
    "  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcb03a9-d15e-4fed-8b76-575fafd71081",
   "metadata": {},
   "source": [
    "PUT YOUR CODE IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a20a36-6223-4153-9219-56a43849c385",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf551a99ee233ec33430d4ba32c4b86f",
     "grade": true,
     "grade_id": "cell-1eb4fea34663618d",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "class EvaluateClassifier(f3dasm.datageneration.DataGenerator):\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def evaluate_classifier(self, model) -> float:\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return accuracy\n",
    "    \n",
    "    def execute(self, experiment_sample) -> None:\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return experiment_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc405024-76b6-44a6-8536-ab1280dd3c95",
   "metadata": {},
   "source": [
    "END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87de80-a37e-4a54-bf61-8627d57259c9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "3.4 _(2 points)_ Evaluate all the experiments and plot the accuracy w.r.t. the regularization parameter $C$. Set the scale of the x-axis to be logarithmic\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa590fd6-5ce3-4d35-aa94-f7ee3eb86999",
   "metadata": {},
   "source": [
    "PUT YOUR CODE IN THE CELL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06e0e6-2b12-411e-a1a8-675854a98e95",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96b39b276d87353783951fae7cdd8bf2",
     "grade": true,
     "grade_id": "cell-6761b8ab399ff28a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea2bb6d-5b0f-4694-8939-78af9742977b",
   "metadata": {},
   "source": [
    "END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb67bfa-06ad-4089-8f18-9bb70fc31a3c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a22637-9a4b-4baf-83a9-e2b20dfede9b",
   "metadata": {},
   "source": [
    "End of the homework!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
